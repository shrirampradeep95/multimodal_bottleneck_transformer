# Multimodal Bottleneck Transformer (MBT)

**Official PyTorch implementation of**  
ğŸ“„ _[Attention Bottlenecks for Multimodal Fusion (NeurIPS 2021)](https://arxiv.org/abs/2107.00135)_

---

## Overview

This repository implements the **Multimodal Bottleneck Transformer (MBT)** from scratch. MBT is a transformer-based architecture that uses **bottleneck tokens** to efficiently fuse visual and audio information. Key features include:

- Support for **AudioSet** and **VGGSound** datasets
- Use of **AST** for audio encoding and **ViT** for video encoding
- Bottleneck fusion blocks at each transformer layer
- Classification using CLS token fusion
- Fully modular, extensible, and dataset-agnostic

---

## ğŸ”§ Architecture

The model processes **video frames** and **log-mel spectrograms** via separate transformer encoders. Bottleneck tokens mediate cross-modal attention:

      [Video Frames]     [Spectrograms]
            â†“                  â†“
       ViT Encoder         AST Encoder
            â†“                  â†“
    [RGB Tokens]         [Audio Tokens]
            â†˜              â†™
    â†˜   Bottleneck Tokens   â†™
    â†’â†’â†’â†’â†’â†’ Fusion Layers â†’â†’â†’â†’â†’â†’
                 â†“
       [CLS Tokens from both]
                 â†“
         Linear Classifier


---

## Core Concepts

### Bottleneck Attention
Instead of full cross-attention (quadratic cost), a small number of shared **bottleneck tokens** attend to both modalities to transfer relevant information.

### CLS Token Fusion
Final classification is done using a linear head on top of the **averaged logits** from audio and video CLS tokens.

### ğŸ” Positional Encoding & Patchification
- **Video**: 8 frames at 25 FPS â†’ 14Ã—14 patches â†’ 1568 tokens
- **Audio**: t-second log-mel spectrogram â†’ 400 tokens (16Ã—16 patches)

---

## Requirements

Install all dependencies using:

```bash
pip install -r requirements.txt

**Key Packages**
torch â€” PyTorch deep learning framework
timm â€” Pretrained Vision Transformers (used for ViT)
einops â€” Tensor manipulation library (used for rearranging tokens)
torchaudio â€” For audio I/O and spectrogram preprocessing
opencv-python â€” For video frame extraction and processing
scikit-learn â€” Evaluation metrics like average precision
tqdm â€” Progress bar for training and data loading
numpy, pandas â€” Standard scientific computing stack

## **Loss Functions**

BCEWithLogitsLoss for AudioSet (multi-label classification)
CrossEntropyLoss for VGGSound (single-label classification)

