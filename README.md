# Multimodal Bottleneck Transformer (MBT)

A PyTorch-based implementation of the **Multimodal Bottleneck Transformer** for audio-visual classification. This project supports training and evaluating models on datasets like **AudioSet** and **VGGSound**, using audio, video, or fused features with cross-modal bottleneck fusion.

## ðŸ§  Key Features

- Multimodal fusion with bottleneck tokens (MBT)
- Supports AudioSet (multi-label) and VGGSound (single-label)
- Training options for audio-only, video-only, or both
- Plug-and-play architecture using PyTorch modules
- Visualization of training loss and evaluation metrics
